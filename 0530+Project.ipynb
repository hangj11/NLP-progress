{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0530+Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1o7zOD1h0y/d9lE7fDaFp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hangj11/NLP-progress/blob/master/0530%2BProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e288_RyDJ_2s",
        "outputId": "ce70fad4-8e27-4871-fc19-68a5a976901c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E29rd3Azt3L",
        "outputId": "db3f1916-e558-4148-fcd1-2f4ecadcfe85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "!pip install keras\n",
        "# Parameters for the model and dataset.\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharacterTable:\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return \"\".join(self.indices_char[x] for x in x)\n",
        "\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = \"0123456789+ \"\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print(\"Generating data...\")\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(\n",
        "        \"\".join(\n",
        "            np.random.choice(list(\"0123456789\"))\n",
        "            for i in range(np.random.randint(1, DIGITS + 1))\n",
        "        )\n",
        "    )\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = \"{}+{}\".format(a, b)\n",
        "    query = q + \" \" * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print(\"Total questions:\", len(questions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oajVjhGT08hd",
        "outputId": "84f33146-8f81-4a73-de45-1ae95503a40c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vectorization...\")\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Validation Data:\")\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfxi6XO21V7k",
        "outputId": "f91c44cd-cc46-4cf9-e6b1-08eb7e9ba033"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Build model...\")\n",
        "num_layers = 1  # Try to add more LSTM layers!\n",
        "\n",
        "model = keras.Sequential()\n",
        "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
        "# Note: In a situation where your input sequences have a variable length,\n",
        "# use input_shape=(None, num_feature).\n",
        "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
        "# As the decoder RNN's input, repeatedly provide with the last output of\n",
        "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
        "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "# The decoder RNN could be multiple layers stacked or a single layer.\n",
        "for _ in range(num_layers):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
        "# of the output sequence, decide which character should be chosen.\n",
        "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRXw-Jtt1pOr",
        "outputId": "9336c107-d9d3-4d64-dee2-92f874dcdf58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               72192     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4, 12)             1548      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print(\"Iteration\", epoch)\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=1,\n",
        "        validation_data=(x_val, y_val),\n",
        "    )\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "        print(\"T\", correct, end=\" \")\n",
        "        if correct == guess:\n",
        "            print(\"☑ \" + guess)\n",
        "        else:\n",
        "            print(\"☒ \" + guess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M0vIVXZ10Az",
        "outputId": "2b630d71-0054-4bbd-f95b-4b82b5f70a2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 32s 19ms/step - loss: 1.7690 - accuracy: 0.3526 - val_loss: 1.5692 - val_accuracy: 0.4082\n",
            "Q 68+80   T 148  ☒ 881 \n",
            "Q 27+334  T 361  ☒ 378 \n",
            "Q 29+68   T 97   ☒ 10  \n",
            "Q 274+27  T 301  ☒ 378 \n",
            "Q 736+397 T 1133 ☒ 101 \n",
            "Q 650+473 T 1123 ☒ 1018\n",
            "Q 9+781   T 790  ☒ 907 \n",
            "Q 273+541 T 814  ☒ 110 \n",
            "Q 143+843 T 986  ☒ 101 \n",
            "Q 0+222   T 222  ☑ 222 \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 1.3544 - accuracy: 0.4928 - val_loss: 1.1630 - val_accuracy: 0.5698\n",
            "Q 71+155  T 226  ☒ 177 \n",
            "Q 49+17   T 66   ☒ 57  \n",
            "Q 85+807  T 892  ☒ 879 \n",
            "Q 9+511   T 520  ☒ 514 \n",
            "Q 649+47  T 696  ☒ 700 \n",
            "Q 777+80  T 857  ☒ 877 \n",
            "Q 53+57   T 110  ☒ 113 \n",
            "Q 919+837 T 1756 ☒ 1797\n",
            "Q 49+50   T 99   ☒ 10  \n",
            "Q 692+599 T 1291 ☒ 1377\n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 1.0086 - accuracy: 0.6274 - val_loss: 0.8957 - val_accuracy: 0.6604\n",
            "Q 482+15  T 497  ☒ 492 \n",
            "Q 734+643 T 1377 ☒ 1289\n",
            "Q 555+222 T 777  ☑ 777 \n",
            "Q 814+643 T 1457 ☒ 1464\n",
            "Q 147+760 T 907  ☒ 894 \n",
            "Q 247+58  T 305  ☒ 302 \n",
            "Q 471+611 T 1082 ☑ 1082\n",
            "Q 26+902  T 928  ☑ 928 \n",
            "Q 39+27   T 66   ☒ 73  \n",
            "Q 27+3    T 30   ☒ 38  \n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.8285 - accuracy: 0.6976 - val_loss: 0.7824 - val_accuracy: 0.7103\n",
            "Q 303+46  T 349  ☒ 357 \n",
            "Q 556+28  T 584  ☒ 587 \n",
            "Q 5+463   T 468  ☒ 467 \n",
            "Q 15+297  T 312  ☑ 312 \n",
            "Q 751+46  T 797  ☒ 792 \n",
            "Q 63+677  T 740  ☒ 731 \n",
            "Q 55+349  T 404  ☒ 402 \n",
            "Q 516+37  T 553  ☒ 557 \n",
            "Q 39+360  T 399  ☒ 492 \n",
            "Q 88+32   T 120  ☒ 122 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.7360 - accuracy: 0.7328 - val_loss: 0.6985 - val_accuracy: 0.7428\n",
            "Q 31+890  T 921  ☒ 926 \n",
            "Q 6+301   T 307  ☒ 306 \n",
            "Q 54+148  T 202  ☒ 102 \n",
            "Q 807+97  T 904  ☒ 806 \n",
            "Q 498+23  T 521  ☒ 522 \n",
            "Q 59+123  T 182  ☒ 181 \n",
            "Q 820+271 T 1091 ☒ 1096\n",
            "Q 671+38  T 709  ☒ 604 \n",
            "Q 87+970  T 1057 ☒ 1052\n",
            "Q 846+35  T 881  ☑ 881 \n",
            "\n",
            "Iteration 6\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.6095 - accuracy: 0.7793 - val_loss: 0.5018 - val_accuracy: 0.8171\n",
            "Q 42+511  T 553  ☑ 553 \n",
            "Q 954+24  T 978  ☑ 978 \n",
            "Q 7+956   T 963  ☑ 963 \n",
            "Q 870+2   T 872  ☑ 872 \n",
            "Q 238+581 T 819  ☒ 818 \n",
            "Q 60+258  T 318  ☑ 318 \n",
            "Q 704+6   T 710  ☑ 710 \n",
            "Q 563+2   T 565  ☑ 565 \n",
            "Q 627+377 T 1004 ☒ 1011\n",
            "Q 46+685  T 731  ☑ 731 \n",
            "\n",
            "Iteration 7\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.3535 - accuracy: 0.8833 - val_loss: 0.2833 - val_accuracy: 0.9161\n",
            "Q 96+198  T 294  ☒ 296 \n",
            "Q 85+492  T 577  ☒ 576 \n",
            "Q 19+636  T 655  ☑ 655 \n",
            "Q 477+39  T 516  ☒ 506 \n",
            "Q 894+53  T 947  ☑ 947 \n",
            "Q 55+274  T 329  ☑ 329 \n",
            "Q 721+69  T 790  ☒ 780 \n",
            "Q 42+37   T 79   ☑ 79  \n",
            "Q 7+472   T 479  ☑ 479 \n",
            "Q 97+793  T 890  ☑ 890 \n",
            "\n",
            "Iteration 8\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.1909 - accuracy: 0.9490 - val_loss: 0.3736 - val_accuracy: 0.8788\n",
            "Q 192+875 T 1067 ☒ 1077\n",
            "Q 120+64  T 184  ☑ 184 \n",
            "Q 133+30  T 163  ☒ 164 \n",
            "Q 168+0   T 168  ☑ 168 \n",
            "Q 24+632  T 656  ☑ 656 \n",
            "Q 583+35  T 618  ☒ 619 \n",
            "Q 50+867  T 917  ☑ 917 \n",
            "Q 57+512  T 569  ☑ 569 \n",
            "Q 59+416  T 475  ☑ 475 \n",
            "Q 64+620  T 684  ☑ 684 \n",
            "\n",
            "Iteration 9\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.1196 - accuracy: 0.9704 - val_loss: 0.0971 - val_accuracy: 0.9748\n",
            "Q 241+480 T 721  ☑ 721 \n",
            "Q 392+317 T 709  ☑ 709 \n",
            "Q 46+69   T 115  ☑ 115 \n",
            "Q 81+763  T 844  ☑ 844 \n",
            "Q 707+5   T 712  ☑ 712 \n",
            "Q 166+877 T 1043 ☑ 1043\n",
            "Q 968+686 T 1654 ☑ 1654\n",
            "Q 741+79  T 820  ☑ 820 \n",
            "Q 575+479 T 1054 ☑ 1054\n",
            "Q 20+874  T 894  ☑ 894 \n",
            "\n",
            "Iteration 10\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.0899 - accuracy: 0.9772 - val_loss: 0.1414 - val_accuracy: 0.9523\n",
            "Q 384+77  T 461  ☑ 461 \n",
            "Q 897+13  T 910  ☑ 910 \n",
            "Q 72+614  T 686  ☑ 686 \n",
            "Q 90+952  T 1042 ☑ 1042\n",
            "Q 75+611  T 686  ☑ 686 \n",
            "Q 484+76  T 560  ☒ 550 \n",
            "Q 447+50  T 497  ☑ 497 \n",
            "Q 282+97  T 379  ☑ 379 \n",
            "Q 152+418 T 570  ☑ 570 \n",
            "Q 311+54  T 365  ☑ 365 \n",
            "\n",
            "Iteration 11\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0642 - accuracy: 0.9846 - val_loss: 0.0671 - val_accuracy: 0.9805\n",
            "Q 43+614  T 657  ☑ 657 \n",
            "Q 8+926   T 934  ☑ 934 \n",
            "Q 376+391 T 767  ☑ 767 \n",
            "Q 948+780 T 1728 ☑ 1728\n",
            "Q 96+44   T 140  ☑ 140 \n",
            "Q 322+968 T 1290 ☒ 1280\n",
            "Q 925+619 T 1544 ☑ 1544\n",
            "Q 803+935 T 1738 ☑ 1738\n",
            "Q 919+83  T 1002 ☑ 1002\n",
            "Q 757+508 T 1265 ☑ 1265\n",
            "\n",
            "Iteration 12\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0535 - accuracy: 0.9864 - val_loss: 0.0328 - val_accuracy: 0.9934\n",
            "Q 619+53  T 672  ☑ 672 \n",
            "Q 872+304 T 1176 ☑ 1176\n",
            "Q 192+507 T 699  ☑ 699 \n",
            "Q 185+178 T 363  ☑ 363 \n",
            "Q 421+75  T 496  ☑ 496 \n",
            "Q 61+98   T 159  ☑ 159 \n",
            "Q 418+224 T 642  ☑ 642 \n",
            "Q 769+557 T 1326 ☑ 1326\n",
            "Q 743+85  T 828  ☑ 828 \n",
            "Q 544+73  T 617  ☑ 617 \n",
            "\n",
            "Iteration 13\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0476 - accuracy: 0.9871 - val_loss: 0.0350 - val_accuracy: 0.9918\n",
            "Q 89+560  T 649  ☑ 649 \n",
            "Q 28+913  T 941  ☑ 941 \n",
            "Q 76+66   T 142  ☑ 142 \n",
            "Q 0+975   T 975  ☒ 974 \n",
            "Q 29+65   T 94   ☑ 94  \n",
            "Q 584+692 T 1276 ☑ 1276\n",
            "Q 104+55  T 159  ☒ 169 \n",
            "Q 860+183 T 1043 ☑ 1043\n",
            "Q 175+9   T 184  ☑ 184 \n",
            "Q 543+373 T 916  ☑ 916 \n",
            "\n",
            "Iteration 14\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0403 - accuracy: 0.9896 - val_loss: 0.0255 - val_accuracy: 0.9946\n",
            "Q 621+6   T 627  ☑ 627 \n",
            "Q 113+319 T 432  ☑ 432 \n",
            "Q 828+71  T 899  ☑ 899 \n",
            "Q 592+803 T 1395 ☑ 1395\n",
            "Q 50+9    T 59   ☑ 59  \n",
            "Q 65+262  T 327  ☑ 327 \n",
            "Q 45+476  T 521  ☑ 521 \n",
            "Q 79+134  T 213  ☑ 213 \n",
            "Q 53+30   T 83   ☑ 83  \n",
            "Q 804+194 T 998  ☑ 998 \n",
            "\n",
            "Iteration 15\n",
            "1407/1407 [==============================] - 25s 17ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0208 - val_accuracy: 0.9959\n",
            "Q 0+757   T 757  ☑ 757 \n",
            "Q 724+510 T 1234 ☑ 1234\n",
            "Q 650+74  T 724  ☑ 724 \n",
            "Q 558+72  T 630  ☑ 630 \n",
            "Q 559+943 T 1502 ☑ 1502\n",
            "Q 777+99  T 876  ☑ 876 \n",
            "Q 10+435  T 445  ☑ 445 \n",
            "Q 445+390 T 835  ☑ 835 \n",
            "Q 355+376 T 731  ☑ 731 \n",
            "Q 715+13  T 728  ☑ 728 \n",
            "\n",
            "Iteration 16\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.0232 - val_accuracy: 0.9944\n",
            "Q 33+15   T 48   ☑ 48  \n",
            "Q 454+973 T 1427 ☑ 1427\n",
            "Q 287+61  T 348  ☑ 348 \n",
            "Q 67+479  T 546  ☑ 546 \n",
            "Q 58+435  T 493  ☑ 493 \n",
            "Q 932+9   T 941  ☑ 941 \n",
            "Q 43+146  T 189  ☑ 189 \n",
            "Q 265+386 T 651  ☑ 651 \n",
            "Q 36+445  T 481  ☑ 481 \n",
            "Q 528+52  T 580  ☑ 580 \n",
            "\n",
            "Iteration 17\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0378 - accuracy: 0.9894 - val_loss: 0.0252 - val_accuracy: 0.9938\n",
            "Q 195+65  T 260  ☑ 260 \n",
            "Q 195+93  T 288  ☑ 288 \n",
            "Q 844+60  T 904  ☑ 904 \n",
            "Q 575+479 T 1054 ☑ 1054\n",
            "Q 15+758  T 773  ☑ 773 \n",
            "Q 983+6   T 989  ☑ 989 \n",
            "Q 74+800  T 874  ☑ 874 \n",
            "Q 4+812   T 816  ☑ 816 \n",
            "Q 45+48   T 93   ☑ 93  \n",
            "Q 106+636 T 742  ☑ 742 \n",
            "\n",
            "Iteration 18\n",
            "1407/1407 [==============================] - 25s 17ms/step - loss: 0.0235 - accuracy: 0.9943 - val_loss: 0.0145 - val_accuracy: 0.9967\n",
            "Q 2+60    T 62   ☑ 62  \n",
            "Q 329+139 T 468  ☑ 468 \n",
            "Q 937+904 T 1841 ☑ 1841\n",
            "Q 47+643  T 690  ☑ 690 \n",
            "Q 333+17  T 350  ☑ 350 \n",
            "Q 960+25  T 985  ☑ 985 \n",
            "Q 671+38  T 709  ☑ 709 \n",
            "Q 783+21  T 804  ☑ 804 \n",
            "Q 798+98  T 896  ☑ 896 \n",
            "Q 534+8   T 542  ☑ 542 \n",
            "\n",
            "Iteration 19\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.0338 - accuracy: 0.9904 - val_loss: 0.0335 - val_accuracy: 0.9900\n",
            "Q 31+22   T 53   ☑ 53  \n",
            "Q 534+59  T 593  ☑ 593 \n",
            "Q 96+84   T 180  ☑ 180 \n",
            "Q 150+79  T 229  ☑ 229 \n",
            "Q 4+979   T 983  ☑ 983 \n",
            "Q 429+249 T 678  ☑ 678 \n",
            "Q 275+63  T 338  ☑ 338 \n",
            "Q 149+72  T 221  ☑ 221 \n",
            "Q 960+25  T 985  ☑ 985 \n",
            "Q 794+438 T 1232 ☑ 1232\n",
            "\n",
            "Iteration 20\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.1659 - val_accuracy: 0.9407\n",
            "Q 152+182 T 334  ☑ 334 \n",
            "Q 798+60  T 858  ☑ 858 \n",
            "Q 91+991  T 1082 ☑ 1082\n",
            "Q 130+461 T 591  ☑ 591 \n",
            "Q 216+1   T 217  ☑ 217 \n",
            "Q 840+914 T 1754 ☑ 1754\n",
            "Q 814+44  T 858  ☑ 858 \n",
            "Q 94+493  T 587  ☑ 587 \n",
            "Q 90+952  T 1042 ☑ 1042\n",
            "Q 172+54  T 226  ☑ 226 \n",
            "\n",
            "Iteration 21\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.0178 - val_accuracy: 0.9944\n",
            "Q 336+48  T 384  ☑ 384 \n",
            "Q 497+84  T 581  ☑ 581 \n",
            "Q 247+58  T 305  ☑ 305 \n",
            "Q 884+632 T 1516 ☑ 1516\n",
            "Q 210+28  T 238  ☑ 238 \n",
            "Q 91+16   T 107  ☑ 107 \n",
            "Q 307+23  T 330  ☑ 330 \n",
            "Q 473+403 T 876  ☑ 876 \n",
            "Q 43+614  T 657  ☑ 657 \n",
            "Q 566+70  T 636  ☑ 636 \n",
            "\n",
            "Iteration 22\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.0364 - accuracy: 0.9897 - val_loss: 0.0249 - val_accuracy: 0.9924\n",
            "Q 947+2   T 949  ☑ 949 \n",
            "Q 7+679   T 686  ☑ 686 \n",
            "Q 49+204  T 253  ☑ 253 \n",
            "Q 98+172  T 270  ☑ 270 \n",
            "Q 790+3   T 793  ☑ 793 \n",
            "Q 448+49  T 497  ☑ 497 \n",
            "Q 711+60  T 771  ☑ 771 \n",
            "Q 908+25  T 933  ☑ 933 \n",
            "Q 0+423   T 423  ☑ 423 \n",
            "Q 249+39  T 288  ☑ 288 \n",
            "\n",
            "Iteration 23\n",
            "1407/1407 [==============================] - 25s 17ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.0175 - val_accuracy: 0.9947\n",
            "Q 33+471  T 504  ☑ 504 \n",
            "Q 62+215  T 277  ☑ 277 \n",
            "Q 12+593  T 605  ☑ 605 \n",
            "Q 935+21  T 956  ☑ 956 \n",
            "Q 158+65  T 223  ☑ 223 \n",
            "Q 65+72   T 137  ☑ 137 \n",
            "Q 999+64  T 1063 ☑ 1063\n",
            "Q 215+882 T 1097 ☑ 1097\n",
            "Q 186+824 T 1010 ☑ 1010\n",
            "Q 940+222 T 1162 ☑ 1162\n",
            "\n",
            "Iteration 24\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.0059 - val_accuracy: 0.9991\n",
            "Q 27+826  T 853  ☑ 853 \n",
            "Q 783+417 T 1200 ☑ 1200\n",
            "Q 822+24  T 846  ☑ 846 \n",
            "Q 608+85  T 693  ☑ 693 \n",
            "Q 419+287 T 706  ☑ 706 \n",
            "Q 590+97  T 687  ☑ 687 \n",
            "Q 638+307 T 945  ☑ 945 \n",
            "Q 21+949  T 970  ☑ 970 \n",
            "Q 534+62  T 596  ☑ 596 \n",
            "Q 90+38   T 128  ☑ 128 \n",
            "\n",
            "Iteration 25\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0249 - accuracy: 0.9930 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
            "Q 787+23  T 810  ☑ 810 \n",
            "Q 20+189  T 209  ☑ 209 \n",
            "Q 915+4   T 919  ☑ 919 \n",
            "Q 954+62  T 1016 ☑ 1016\n",
            "Q 418+74  T 492  ☑ 492 \n",
            "Q 983+77  T 1060 ☑ 1060\n",
            "Q 305+64  T 369  ☑ 369 \n",
            "Q 304+590 T 894  ☑ 894 \n",
            "Q 4+51    T 55   ☑ 55  \n",
            "Q 742+146 T 888  ☑ 888 \n",
            "\n",
            "Iteration 26\n",
            "1407/1407 [==============================] - 25s 17ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0136 - val_accuracy: 0.9958\n",
            "Q 17+35   T 52   ☑ 52  \n",
            "Q 6+131   T 137  ☑ 137 \n",
            "Q 105+500 T 605  ☑ 605 \n",
            "Q 754+2   T 756  ☑ 756 \n",
            "Q 935+829 T 1764 ☑ 1764\n",
            "Q 243+96  T 339  ☑ 339 \n",
            "Q 88+18   T 106  ☑ 106 \n",
            "Q 627+46  T 673  ☑ 673 \n",
            "Q 979+831 T 1810 ☑ 1810\n",
            "Q 269+822 T 1091 ☑ 1091\n",
            "\n",
            "Iteration 27\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
            "Q 711+60  T 771  ☑ 771 \n",
            "Q 28+552  T 580  ☑ 580 \n",
            "Q 32+56   T 88   ☑ 88  \n",
            "Q 961+6   T 967  ☑ 967 \n",
            "Q 386+683 T 1069 ☑ 1069\n",
            "Q 9+994   T 1003 ☑ 1003\n",
            "Q 839+769 T 1608 ☑ 1608\n",
            "Q 297+322 T 619  ☑ 619 \n",
            "Q 902+63  T 965  ☑ 965 \n",
            "Q 329+139 T 468  ☑ 468 \n",
            "\n",
            "Iteration 28\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.0095 - val_accuracy: 0.9976\n",
            "Q 403+692 T 1095 ☑ 1095\n",
            "Q 395+316 T 711  ☑ 711 \n",
            "Q 565+350 T 915  ☑ 915 \n",
            "Q 23+684  T 707  ☑ 707 \n",
            "Q 13+38   T 51   ☑ 51  \n",
            "Q 51+57   T 108  ☑ 108 \n",
            "Q 689+766 T 1455 ☑ 1455\n",
            "Q 162+6   T 168  ☑ 168 \n",
            "Q 3+431   T 434  ☑ 434 \n",
            "Q 565+979 T 1544 ☑ 1544\n",
            "\n",
            "Iteration 29\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.0915 - val_accuracy: 0.9674\n",
            "Q 89+995  T 1084 ☑ 1084\n",
            "Q 835+123 T 958  ☑ 958 \n",
            "Q 404+768 T 1172 ☑ 1172\n",
            "Q 103+84  T 187  ☑ 187 \n",
            "Q 898+82  T 980  ☑ 980 \n",
            "Q 169+93  T 262  ☑ 262 \n",
            "Q 439+50  T 489  ☑ 489 \n",
            "Q 106+72  T 178  ☑ 178 \n",
            "Q 3+344   T 347  ☑ 347 \n",
            "Q 44+36   T 80   ☑ 80  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PQe17nIS2Bli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}